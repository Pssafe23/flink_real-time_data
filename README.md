
本项目是跟着尚硅谷做的flink实时数仓的学习项目

# 流程
## 框架

### ods层

- 业务数据

>先从业务数据入手，业务数据首先模拟生成后由springboot的程序存放到mysql，在从mysql中将数据通过flinkcdc存入kafka(ods)

- 日志数据

>日志数据则是模拟生成后直接存入kafka(ods)

### dwd层

- 业务数据
> 因为直接通过flinkapp程序拉取数据的话，都存入一个topic，而mysql中的数据表，46张，有维度，也有事实，所以通过测分流，将数据表进行分开；我们在操作mysql时，操作的每一步，都是主流，为什么呢？因为ods层开着flinkcdc，实时监控着；之后，广播流则是直接监控mysql其中一张表，这张表是监控表的操作的，之后通过分流，将维度表存入hbase，将事实表存入kafka(dwd)，没有表就创建，之后将主流数据存入进去

- 日志数据
> 将日志数据进行分流，页面日志输入到主流，而启动日志输入到启动流，曝光日志输入到曝光输出流，并对新老用户进行识别。

### dwm层(重点)

**通过计算把一种明细转变为另一种明细以应对后续 的统计**

➢ 学会利用状态（state）进行去重操作。（需求：UV 计算） 
➢ 学会利用 CEP 可以针对一组数据进行筛选判断。需求：跳出行为计算 
➢ 学会使用 intervalJoin 处理流 join 
➢ 学会处理维度关联，并通过缓存和异步查询对其进行性能优化。

主要是访客 UV 计算（每日活跃用户）和跳出行为行为计算

- UniqueVisit
> 其一，是识别出该访客打开的第一个页面，表示这个访客开始进入我们的应用
> 其二，由于访客可以在一天中多次进入应用，所以我们要在一天的范围内进行去重

- UserJumpDetail
> 关注跳出率，可以看出引流过来的访客是否能很快的被吸引，渠道引流过来的用户之间 的质量对比，对于应用优化前后跳出率的对比也能看出优化改进的成果。

> ➢ 该页面是用户近期访问的第一个页面 这个可以通过该页面是否有上一个页面（last_page_id）来判断，如果这个表示为空， 就说明这是这个访客这次访问的第一个页面。 
> ➢ 首次访问之后很长一段时间（自己设定），用户没继续再有其他页面的访问。

- 订单宽表
>订单是统计分析的重要的对象，围绕订单有很多的维度统计需求，比如用户、地区、商品、品类、品牌等等。

>为了之后统计计算更加方便，减少大表之间的关联，所以在实时计算过程中将围绕订单的相关数据整合成为一张订单的宽表。

![image](https://github.com/Pssafe23/flink_real-time_data/assets/88642338/15dc53f7-08ce-43c3-9971-c9bb8496870e)


>➢ 事实数据和事实数据关联，其实就是流与流之间的关联。 (使用intervaljoin)
>➢ 事实数据与维度数据关联，其实就是流计算中查询外部数据源。

- 事实数据与维度数据
> 外部数据源的查询常常是流式计算的 性能瓶颈，所以我们需要在上面实现的基础上进行一定的优化。我们这里使用旁路缓存。

![image](https://github.com/Pssafe23/flink_real-time_data/assets/88642338/0d6ed35f-c311-4b55-b26d-eecc356ec795)






> 使用redis+hbase，如果查询时，首先在redis先查看缓存，如果没有，就直接查询hbase数据，之后将维度数据同步到redis，由于维度表一般更改次数少，所以下一次查询就不用再到hbase，而是直接从redis拿取 ，如果数据更新的话，先删除redis，在更该hbase中的数据，之后新的数据需要重新到hbase拿取，在缓存到redis。

- 异步查询
> 在 Flink 流处理过程中，经常需要和外部系统进行交互，用维度表补全事实表中的字段。

![image](https://github.com/Pssafe23/flink_real-time_data/assets/88642338/567b0ecd-4d8d-4d32-ad3a-db485c2523c4)




> 异步查询实际上是把维表的查询操作托管给单独的线程池完成，这样不会因为某一个查询造成阻塞，单个并行可以连续发送多个请求，提高并发效率。


>无需等待数据的一个延迟，当然，换来的就是数据有一定的乱序

>关联用户维度,关联省市维度,关联 SKU 维度,关联 SPU 维度,关联品类维度

- 支付宽表






### dws层(重点)

**我们在之前通过分流等手段，把数据分拆成了独立的 Kafka Topic。那么接下来如何处 理数据，就要思考一下我们到底要通过实时计算出哪些指标项。**

➢ DWS 层主要是基于 DWD 和 DWM 层的数据进行轻度聚合统计 
➢ 掌握利用 union 操作实现多流的合并 
➢ 掌握窗口聚合操作 
➢ 掌握对 clickhouse 数据库的写入操作 
➢ 掌握用 FlinkSQL 实现业务 
➢ 掌握分词器的使用 
➢ 掌握在 FlinkSQL 中自定义函数的使用

![image](https://github.com/Pssafe23/flink_real-time_data/assets/88642338/8f251e27-da1d-4390-b152-c6c41b9abd9b)


![image](https://github.com/Pssafe23/flink_real-time_data/assets/88642338/a1affd45-9791-42a8-b466-8eb140eda27b)


 ###  DWS 层的定位是什么 
 
>➢ 轻度聚合，因为 DWS 层要应对很多实时查询，如果是完全的明细那么查询的压力是非 常大的。
> ➢ 将更多的实时数据以主题的方式组合起来便于管理，同时也能减少维度查询的次数。

设计一张 DWS 层的表其实就两件事：维度和度量(事实数据) 
➢ 度量包括 PV、UV、跳出次数、进入页面数(session_count)、连续访问时长 
➢ 维度包括在分析中比较重要的几个字段：渠道、地区、版本、新老用户进行聚合


关键词主题这个主要是为了大屏展示中的字符云的展示效果，用于感性的让大屏观看者 感知目前的用户都更关心的那些商品和关键词。 关键词的展示也是一种维度聚合的结果，根据聚合的大小来决定关键词的大小。 关键词的第一重要来源的就是用户在搜索栏的搜索，另外就是从以商品为主题的统计中 获取关键词。

![image](https://github.com/Pssafe23/flink_real-time_data/assets/88642338/452cc1f4-81b7-4742-ac89-08f768e5d1a3)




